<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Music and Lyrics : Genre classification based on musical features and lyrics." />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Music and Lyrics</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/josh-jacobson/genre-classification">View on GitHub</a>

          <h1 id="project_title">Music and Lyrics</h1>
          <h2 id="project_tagline">Genre classification based on musical features and lyrics.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/josh-jacobson/genre-classification/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/josh-jacobson/genre-classification/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a name="abstract" class="anchor" href="#abstract"><span class="octicon octicon-link"></span></a>Abstract</h3>

<p>Our goal is to make a system that is able to determine a song’s genre, based on a combination of low-level audio features and lyrical content. We tend to combine the most relevant low level and lyrical features, utilizing boosting to create the most powerful classification tool we can.</p>

<h3>
<a name="motivation" class="anchor" href="#motivation"><span class="octicon octicon-link"></span></a>Motivation</h3>

<p>Our interest in this topic arises from a passion for music, and the process of classifying genres with a machine learning method will reveal a lot about the fundamental characteristics of different genres and the underlying mathematical nature of all music.</p>

<p>This work has many practical applications.  For instance, it may be used for cataloguing music when it’s uploaded to a library, or as a basis for a song suggestion application. In theory, a major extension of this learning algorithm could even allow for computer construction of basic song forms of a particular genre.</p>

<p>The applications of this feature extraction and use may also reveal important characteristics about what lyrical tendencies and audio features are determinant in a song's qualities. This knowledge has applications beyond genre classification and could be used for many other applications of audio analysis and classification.</p>

<h3>
<a name="tools" class="anchor" href="#tools"><span class="octicon octicon-link"></span></a>Tools</h3>

<p>We are using Marsyas (Music Analysis, Retrieval and Synthesis for Audio Signals), an open-source audio processing framework written by George Tzanetakis. This framework provides a number of useful tools for Music Information Retrieval applications like ours, and we use this software to extract features from audio files in our dataset.</p>

<p>We are also using the ChartLyrics API in order to fetch lyrics for each of the songs. These lyrics are used alongside audio features as input to our learner.</p>

<h3>
<a name="audio-features" class="anchor" href="#audio-features"><span class="octicon octicon-link"></span></a>Audio Features</h3>

<p>In our initial analysis of data, we have begun work with two main audio feature classifiers. We have a matlab script that compiles tempo information on all of our songs, for use classification in WEKA. Tempo is one of our initial features because of its dramatic variation between different styles of music, a distinction that may prove useful in distinguishing between faster (metal) and slower (reggae) genres. Our additional audio feature is Mel-Frequency Cepstral Coefficient (MFCC) analysis. MFCCs are designed to capture short-term spectral-based features and, though initially developed for vocal recognition, have proven highly effective in musical classification. 
Research by Tzanetakis suggests that pitch is also a power classification tool for genre classification. Unfortunately, we've had a number of issues attempting to extract pitch. Despite attempts with python binding enabled Marsyas, and older versions of Marsyas, we have yet to extract meaningful input. This is something we hope to achieve in the week. Alternatively, we will research other meaningful audio features and find another to extract.</p>

<h3>
<a name="lyrical-analysis--classification" class="anchor" href="#lyrical-analysis--classification"><span class="octicon octicon-link"></span></a>Lyrical Analysis &amp; Classification</h3>

<p>Brief summary of data acquisition, sanitation, setbacks, and classification. </p>

<h3>
<a name="initial-results" class="anchor" href="#initial-results"><span class="octicon octicon-link"></span></a>Initial Results</h3>

<p>We've had success in using Marsyas to extract features from the audio files in our dataset, of which there are 100 in each of 8 genres. We first created a collection file for each genre:</p>

<pre><code>$ ./mkcollection -c blues.mf -l blues ~/Desktop/genres/blues/
$ ./mkcollection -c country.mf -l country ~/Desktop/genres/country/ 
$ ./mkcollection -c disco.mf -l disco ~/Desktop/genres/disco/
$ ./mkcollection -c hiphop.mf -l hiphop ~/Desktop/genres/hiphop/
$ ./mkcollection -c metal.mf -l metal ~/Desktop/genres/metal/
$ ./mkcollection -c pop.mf -l pop ~/Desktop/genres/pop/
$ ./mkcollection -c reggae.mf -l reggae ~/Desktop/genres/reggae/
$ ./mkcollection -c rock.mf -l rock ~/Desktop/genres/rock/
</code></pre>

<p>and then used these collections to extract features based on genre.</p>

<pre><code>$ ./bextract -sv blues.mf country.mf disco.mf -w genres.arff -p genres.mpl 
</code></pre>

<p>Our results.</p>

<h3>
<a name="dataset" class="anchor" href="#dataset"><span class="octicon octicon-link"></span></a>Dataset</h3>

<p>We’re using the GTZAN Dataset, which contains 10 genres with 100 musical excerpts each. Given our focus on lyrics, we've decided to exclude jazz and classical since they are mainly instrumental genres. The audio files are each 30 seconds long, and are mono .wav files with a sample rate of 22,050 Hz and a bit depth of 16 bits per sample.</p>

<p>The audio comes from a number of sources, including radio and field recordings in addition to excerpts from normal studio-recorded CD’s. This variation allows for a higher level of robustness in evaluating our learner.</p>

<p>As provided directly from the Marsyas website, the GTZAN audio excerpts are unlabeled -- each filename is just the genre and a number from 0 to 99. However, Bob Sturm has provided song names and artists for most of the excerpts (his paper with this information is cited below). We have filled in in some of the gaps in his labeling using song identification tools like Shazam, and we use this information in order to fetch lyrics for the songs.</p>

<h3>
<a name="our-team" class="anchor" href="#our-team"><span class="octicon octicon-link"></span></a>Our Team</h3>

<p>Moritz Gellner (<a href="https://github.com/moritzg91" class="user-mention">@moritzg91</a>)</p>

<p>Josh Jacobson (<a href="https://github.com/josh-jacobson" class="user-mention">@josh-jacobson</a>)</p>

<p>Carson Potter (<a href="https://github.com/cpottamus" class="user-mention">@cpottamus</a>)</p>

<p>Sam Toizer (<a href="https://github.com/sammysf" class="user-mention">@sammysf</a>)</p>

<p>We're all seniors at Northwestern University, and this is our final project for Machine Learning (EECS 349) with Bryan Pardo.</p>

<h3>
<a name="references" class="anchor" href="#references"><span class="octicon octicon-link"></span></a>References</h3>

<p>Basili et al. “Classification of Musical Genre: A Machine Learning Approach.”</p>

<p>Cuthbert, et al. "Feature Extraction and Machine Learning on Symbolic Music Using the music21 Toolkit". 12th International Society for Music Information Retrieval Conference, 2011. <a href="http://ismir2011.ismir.net/papers/PS3-6.pdf">http://ismir2011.ismir.net/papers/PS3-6.pdf</a>.</p>

<p>Li, et al. "A Comparative Study on Content-Based Music Genre Classification". SIGIR. 2003, July 28 - August 1. Web. 1 Dec., 2013.</p>

<p>Lidy, Thomas. "Marsyas and Rhythm Patterns: Evaluation of two music genre classification systems." <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.1952&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.144.1952&amp;rep=rep1&amp;type=pdf</a>.</p>

<p>Mandel, et al. "Song Level Features and Support Vector Machines for Music Classification". 2005, Queen Mary University, London.</p>

<p>Mathieu, et al. "Yaafe, an Easy to Use and Efficient Audio Feature Extraction Software." Institut Telecom. <a href="http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=10395">http://biblio.telecom-paristech.fr/cgi-bin/download.cgi?id=10395</a>.</p>

<p>Sturm, Bob L., 2012. "An Analysis of the GTZAN Music Genre Dataset", Proc. ACM Workshop MIRUM, Nara, Japan, Nov. 2012. <a href="http://doi.acm.org/10.1145/2390848.2390851">http://doi.acm.org/10.1145/2390848.2390851</a>.</p>

<p>Tzanetakis, George. "Marsyas: A Framework For Audio Analysis." Web. 2 Dec. 2013. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.4572&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.83.4572&amp;rep=rep1&amp;type=pdf</a></p>

<p>Tzanetakis, George. "Marsyas-0.2: A Case Study in Implementing Music Information Retrieval Systems." Web. 2 Dec. 2013.</p>

<p>Tzanetakis, et al. "Pitch Histograms in Audio and Symbolic Music Information Retrieval." <a href="http://www.cs.cmu.edu/%7Egtzan/work/pubs/ismir02gtzan.pdf">http://www.cs.cmu.edu/~gtzan/work/pubs/ismir02gtzan.pdf</a>.</p>

<p>Tzanetakis, G., and Cook, P. "Musical Genre Classification of Audio Signals." IEEE Transactions on Speech and Audio Processing 10.5 (2002): 293-302. Web. 12 Nov. 2013. <a href="http://dspace.library.uvic.ca:8080/bitstream/handle/1828/1344/tsap02gtzan.pdf?sequence=1">http://dspace.library.uvic.ca:8080/bitstream/handle/1828/1344/tsap02gtzan.pdf?sequence=1</a>.</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Music and Lyrics maintained by <a href="https://github.com/josh-jacobson">josh-jacobson</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
