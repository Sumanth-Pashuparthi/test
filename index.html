<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Genre Classification : Classifying genres based on musical features (extracted using Marsyas) and lyrics." />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Genre Classification</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/josh-jacobson/genre-classification">View on GitHub</a>

          <h1 id="project_title">Genre Classification</h1>
          <h2 id="project_tagline">Classifying genres based on musical features (extracted using Marsyas) and lyrics.</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/josh-jacobson/genre-classification/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/josh-jacobson/genre-classification/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h3>
<a name="abstract" class="anchor" href="#abstract"><span class="octicon octicon-link"></span></a>Abstract</h3>

<p>We would like to make a system that is able to determine a song’s genre, based on a combination of low-level audio features and lyrical content. We tend to combine the most relevant low level and lyrical features, utilizing boosting to create the most powerful classification tool we can.</p>

<h3>
<a name="motivation" class="anchor" href="#motivation"><span class="octicon octicon-link"></span></a>Motivation</h3>

<p>Our interest in this topic arises from a passion for music, and the process of classifying genres with a machine learning method will reveal a lot about the fundamental characteristics of different genres and the underlying mathematical nature of all music.</p>

<p>This work has many practical applications.  For instance, it may be used for cataloguing music when it’s uploaded to a library, or as a basis for a song suggestion application. In theory, a major extension of this learning algorithm could even allow for computer construction of basic song forms of a particular genre.</p>

<p>The applications of this feature extraction and use may also reveal important characteristics about what lyrical tendencies and audio features are determinant in a song's qualities. This knowledge has applications beyond genre classification and could be used for many other applications of audio analysis and classification.</p>

<h3>
<a name="initial-results" class="anchor" href="#initial-results"><span class="octicon octicon-link"></span></a>Initial Results</h3>

<p>We've had success in using Marsyas to extract features from the audio files in our dataset, of which there are 100 in each of 8 genres. We first created a collection file for each genre:</p>

<pre><code>$ ./mkcollection -c blues.mf -l blues ~/Desktop/genres/blues/
$ ./mkcollection -c country.mf -l country ~/Desktop/genres/country/ 
$ ./mkcollection -c disco.mf -l disco ~/Desktop/genres/disco/
$ ./mkcollection -c hiphop.mf -l hiphop ~/Desktop/genres/hiphop/
$ ./mkcollection -c metal.mf -l metal ~/Desktop/genres/metal/
$ ./mkcollection -c pop.mf -l pop ~/Desktop/genres/pop/
$ ./mkcollection -c reggae.mf -l reggae ~/Desktop/genres/reggae/
$ ./mkcollection -c rock.mf -l rock ~/Desktop/genres/rock/
</code></pre>

<p>and then used these collections to extract features based on genre.</p>

<pre><code>
$ ./bextract -sv blues.mf country.mf disco.mf -w genres.arff -p genres.mpl 

</code></pre>

<p>Our results.</p>

<h3>
<a name="dataset" class="anchor" href="#dataset"><span class="octicon octicon-link"></span></a>Dataset</h3>

<p>We’re considering using the GTZAN Dataset, which contains 1,000 musical excerpts, each 30 seconds long. The dataset represents an even distribution of 10 genres, so there are 100 songs of each genre. The audio files are all mono and in .wav format, with a sample rate of 22,050 Hz and a bit depth of 16 bits per sample.</p>

<p>The audio comes from a number of sources, including radio and field recordings in addition to excerpts from normal studio-recorded CD’s. This variation allows for a higher level of robustness in evaluating our learner. The large volume of recordings in the dataset will also allow us flexibility in constructing training and validation sets, and potentially evaluating the learning algorithm using cross-validation.</p>

<p>The biggest probably issue with the GTZAN dataset is the incomplete labelling of artists and titles, due to the large period of collection of the songs by Tzanetakis. We're working with Professor Pardo to either implement a solution using a song discovery tool such as Shazam or SoundHound, or to find an alternative, more labelled, dataset. Knowing the song information is critical for finding the lyrics.</p>

<h3>
<a name="our-team" class="anchor" href="#our-team"><span class="octicon octicon-link"></span></a>Our Team</h3>

<p>Moritz Gellner (<a href="https://github.com/moritzg91" class="user-mention">@moritzg91</a>)
Josh Jacobson (<a href="https://github.com/josh-jacobson" class="user-mention">@josh-jacobson</a>)
Carson Potter (<a href="https://github.com/cpottamus" class="user-mention">@cpottamus</a>)
Sam Toizer (<a href="https://github.com/sammysf" class="user-mention">@sammysf</a>)</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Genre Classification maintained by <a href="https://github.com/josh-jacobson">josh-jacobson</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
